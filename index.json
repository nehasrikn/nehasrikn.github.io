[{"authors":null,"categories":null,"content":"Hi there ðŸ‘‹! Iâ€™m a second-year PhD student in the Department of Computer Science at the University of Maryland, College Park where I work with Profs. Rachel Rudinger and Jordan Boyd-Graber.\nIâ€™m a member of the Computational Linguistics and Information Processing (CLIP) Lab in UMIACS.\nBefore coming to Maryland, I worked as a Machine Learning Engineer at Lyft on the Applied Machine Learning team, and before that, I received my Bachelorâ€™s and Masterâ€™s degrees in Computer Science from the University of Texas at Austin, where I was working with Jessy Li on elaboration during text simplification.\nMy research interests lie in natural language processing, particularly in natural language understanding, including problems such as commonsense reasoning, textual inference, and pragmatics.\n","date":1651363200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1651363200,"objectID":"72e395434d30f364d5fd47a6317efcd4","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Hi there ðŸ‘‹! Iâ€™m a second-year PhD student in the Department of Computer Science at the University of Maryland, College Park where I work with Profs. Rachel Rudinger and Jordan Boyd-Graber.","tags":null,"title":"Neha Srikanth","type":"authors"},{"authors":["Neha Srikanth","Rachel Rudinger"],"categories":null,"content":"","date":1651363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651363200,"objectID":"080f73726c8edfb69e7c9716371eb3f4","permalink":"https://nehasrikn.github.io/publication/context-editing/","publishdate":"2022-07-01T00:00:00Z","relpermalink":"/publication/context-editing/","section":"publication","summary":"When strong partial-input baselines reveal artifacts in crowdsourced NLI datasets, the performance of full-input models trained on such datasets is often dismissed as reliance on spurious correlations. We investigate whether state-of-the-art NLI models are capable of overriding default inferences made by a partial-input baseline. We introduce an evaluation set of 600 examples consisting of perturbed premises to examine a RoBERTa model's sensitivity to edited contexts. Our results indicate that NLI models are still capable of learning to condition on context--a necessary component of inferential reasoning--despite being trained on artifact-ridden datasets.","tags":[],"title":"Partial-input baselines show that NLI models can ignore context, but they don't.","type":"publication"},{"authors":["Neha Srikanth","Junyi Jessy Li"],"categories":null,"content":"","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776000,"objectID":"6cf9e97ad4f8838b5d5016c216ed2f8a","permalink":"https://nehasrikn.github.io/publication/elab-simple/","publishdate":"2021-08-01T00:00:00Z","relpermalink":"/publication/elab-simple/","section":"publication","summary":"Much of modern-day text simplification research focuses on sentence-level simplification,transforming original, more complex sentences into simplified versions. However,adding content can often be useful when difficult concepts and reasoning need to be explained. In this work, we present the first datadriven study of content addition in text simplification, which we call elaborative simplification. We introduce a new annotated dataset of 1.3K instances of elaborative simplification in the Newsela corpus, and analyze how entities, ideas, and concepts are elaborated through the lens of contextual specificity. We establish baselines for elaboration generation using large-scale pre-trained language models, and demonstrate that considering contextual specificity during generation can improve performance. Our results illustrate the complexities of elaborative simplification, suggesting many interesting directions for future work.","tags":[],"title":"Elaborative Simplification: Content Addition and Explanation Generation in Text Simplification","type":"publication"}]